# Aleatoric Uncertainty Estimation for Dense Stereo Matching via CNN Based Cost Volume Analysis 论文阅读



[https://www.researchgate.net/publication/346096130_Aleatoric_Uncertainty_Estimation_for_Dense_Stereo_Matching_via_CNN-based_Cost_Volume_Analysis](https://www.researchgate.net/publication/346096130_Aleatoric_Uncertainty_Estimation_for_Dense_Stereo_Matching_via_CNN-based_Cost_Volume_Analysis)

# 摘要
在上篇文章中，我们知道了可以通过去分析 cost volume 来估计 confidence。得到的confidence map每一个像素是一个confidence 得分，解释为该像素位置的视差估计得多准。比如0.8就比0.5估计得准确。但是我们不能知道，这个不确定是多少？也就是说我们只知道这个像素位置的视差估计得不准确，但是具体有多不准确，我们无从得知。基于这个背景，作者在CVA-Net的基础上，提出了新的三种**不确定性模型**来量化**不确定性**（uncertainty）。
<br />
<br />
<br />
<br />


# 量化不确定性
为了准确地量化过程中固有的不确定性，有必要考虑所有潜在的不确定性来源。通常有两种类型的不确定性: **任意不确定性（aleatoric  uncertainty）**和**认知不确定性（epistemic uncertainty）**。
任意不确定性是由 natural variability 引起的，并包含在数据中。在这种情况下，natural variability 被理解为所考虑过程的可变、非确定性或简单的不可预测行为。相比之下，认知不确定性解释了对问题域的有限知识和用于设计或训练预测模型的简化。

在深度学习的背景下，不确定性通常也被区分为这两种情况。在设计或学习模型时，任意不确定性无法降低，因为它是固有的在数据中，因此独立于模型定义。但是，可以将认知不确定性最小化，以更多 (多样化) 训练数据的形式提供附加信息，从而可以形成更准确地表示基础过程的模型。**然而，这两种不确定性之间的差异不仅可以在理论背景中看到，还可以在其量化的实际方法中看到：可以直接基于数据预测任意不确定性，另一方面，认知不确定性通常是基于抽样方法估计。**

从密集立体匹配的角度来看，任意不确定性解释了传感器噪声、遮挡和匹配模糊等影响，这些影响是由场景中的无纹理区域或重复模式引起的。 另一方面，认知不确定性考虑简化匹配过程的假设，例如搜索范围的限制或理想情况下的极线校正，以及训练数据中缺少的特征，例如暗示某种几何形状的纹理和阴影形状。 请注意，在这项工作中，我们只关注**任意不确定性的估计**，认知不确定性不在考虑范围。 

与仅使用二元分类模型的先前工作相比，这里所提出的 CNN 适用于并针对三种不同的不确定性模型进行训练：通过**二元分类的置信度估计**、**残差学习**和**概率建模**。 此外，除了对隐式假设以及优缺点进行理论讨论外，我们的网络的三个变体还基于实验进行了评估，扩展了对三种不同密集立体匹配方法已经详尽的评估。 
<br />
<br />
<br />
<br />


# 网络模型
与原CVA-Net一致，但考虑的视差范围不同，原CVA-Net考虑的是256，这里考虑的是192。那么相应的cost volume 的深度的也应该为192。减少成本体积的深度，从而减少立体图像对中潜在对应的搜索范围，降低了面临模糊匹配结果的风险，这通常会导致更高准确度的视差图。
<div align=center><img src="/posts/aleatoric_unc/network.png" width="  "></div>
<br />
<br />
<br />
<br />

# 不确定性模型
虽然立体图像的视差估计通常是使用参考数据来学习的，但这些数据通常不适用于相关的不确定性。 尽管如此，为了能够学习不确定性估计的任务，通常会假设一个特定的不确定性模型，从而允许**从估计的和ground truth视差之间的偏差中隐含地学习不确定性**。 虽然在我们之前的工作中使用二元分类模型来学习置信度，但在这项工作中，我们讨论了两个额外的不确定性模型，并用于训练我们网络的不同变体：**基于残差的模型**和**概率模型**。 除了不同的损失函数外，可能还需要对最终网络层进行微调以满足三个变体的不同结果空间，这将在后续段落中详细解释。
<br />
<br />
<br />
<br />

## 二元分类
置信度是对视差估计的信任，它可以用这个估计正确的概率来表示。 因此，置信度估计通常被实现为二元分类问题：当网络将视差估计分类为正确或不正确时，正确的概率被用作置信度分数。 为了获得这个概率，我们的网络最后一层的结果被送到一个 sigmoid 非线性层。 二进制类标签的gt（ground truth）来自错误度量：$|d_{est} - d_{gt}|<3\ pixels$或者$|d_{est} - d_{gt}|<(d_{gt}*0.05)$。 使用预测的置信度分数$\gamma$和地面实况类别标签$\hat{\gamma}$，我们网络的第一个变体通过最小化加权二元交叉熵损失进行训练：
$$
\mathcal{L}\_{BC} = \frac{1}{N} \sum_{i=1}^N w_i \cdot H(\gamma_i,\hat{\gamma}_i)
$$

$$
w_i = \hat{\gamma_i} \cdot (w_{corr}-1)+1
$$
$$
H(\gamma, \hat{\gamma}) = -\hat{\gamma} \cdot \log (\gamma)-(1-\hat{\gamma}) \cdot \log (1-\gamma)
$$

其中$N$是有效视差的像素数（具有已知的GT视差的像素数），它们形成一个小批量，因此在一次前向传递中一起处理。 虽然函数$H$计算标准二元交叉熵，但具有正确视差估计的样本是由不正确和正确训练样本$w_{corr}$之间的比率加权。 损失函数中考虑了这个比率来解释不平衡的训练集，这会阻止网络学习更好地预测更频繁的类别。
<br />
<br />
<br />
<br />

## 残差模型
虽然置信度估计只允许评估视差分配是否正确，但误差的大小也可能令人感兴趣。 为了量化误差，训练网络以预测**视差残差**是一种常用方法，即像素的估计值与其真实视差之间的差异。 我们将这种方法应用于我们的第二个变体，将不确定性解释为视差预测误差的函数，这是由我们的 CNN 使用以下损失函数学习的

$$
\mathcal{L}\_{Res}= \frac{1}{N} \sum_{i=1}^N |\Delta d_i-(\hat{d}_i - d_i)|,
$$

其中$d$是估计的视差，$\hat{d}$是GT视差。由CNN直接使用网络最终层的结果来预测视差残差$\Delta d$，而无需应用任何非线性。
<br />
<br />
<br />
<br />

## 概率模型
对于第三个也是最后一个变体，学习预测任意不确定性的任务以贝叶斯方式解释。这通常是通过指定概率分布来描述数据中包含的不确定性来实现的，在训练过程中其可能性最大化。估计的视差和不确定性值用作此概率分布的参数，而GT视差用作观测值。使用这个公式，可以以隐式方式将任意不确定性学习为方差或标准偏差（取决于选择的概率分布），从而避免了对不确定性的参考的需要。基于L1范数在训练CNN进行视差回归任务的背景下的常见用法 ，我们使用Laplace分布来描述任意不确定性。为了能够使用通用优化器，我们基于深度学习的优化过程的目标被表述为这种分布的负对数似然

$$
-\log p(\hat{d}_i | d_i) \propto \frac{\sqrt{2}}{\sigma_i}|d_i-\hat{d}_i|+\log (\sigma_i),
$$

其中，$d$是估计的视差，$\hat{d}$是GT视差。$\sigma$是假设的拉普拉斯分布的标准差，它表示各个像素的任意不确定性。同时在loss函数中替换$s = log(\sigma)$，通过这种修改，我们的网络被训练用来预测对数标准差，这使得训练过程中在数值上更加稳定，并防止损失函数除以0，因此损失函数定义如下：

$$
\mathcal{L}\_{Prob}=\frac{1}{N} \sum_{i=1}^N \frac{\sqrt{2}}{\exp(s_i)}|d_i-\hat{d}_i|+s_i
$$




