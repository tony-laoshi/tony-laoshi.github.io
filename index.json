[{"categories":["SLAM"],"content":"相关链接 标题：Towards Robust Indoor Vision SLAM and Dense Reconstruction for Mobile Robots 作者：Zhang, W; Wang, S; Haala, N. 来源：ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences; Gottingen Vol. V-1-2022, (2022): 211-219. DOI：10.5194/isprs-annals-V-1-2022-211-2022 动机 当前视觉SLAM可以很好的构建各种室内场景，但大多应用于室内小空间，且通常在纹理良好的环境中。 在大型室内场景的实际应用中，它们缺乏鲁棒性，无法构建全局一致的地图。 为此，在这篇文章中作者提出了一种新颖的系统，可以稳健地解决现有视觉 SLAM 遇到的问题，例如弱纹理和长期漂移。 整体思路 通过结合来自车轮里程计的信息，可以在没有纹理的情况下平滑地预测机器人位姿。 通过对齐基于截断有符号距离函数 (TSDF) 的子图来利用几何线索，以最大限度地减少长期漂移。 为了重建更完整和准确的稠密图，利用颜色信息和全局束调整（global BA）的优化结果来细化传感器获得的深度图。 结果 在公共数据集和自收集数据集上验证了所提出方法的准确性和鲁棒性，并展示了每个模块的互补性。 基于高精度ground-truth的评估结果表明，轨迹估计的平均绝对轨迹误差（ATE）从21 cm提高到2 cm，重建地图的平均精度为8 cm。 介绍 在目前阶段激光SLAM表现出强大的性能，视觉SLAM相比较之下缺乏足够的鲁棒性，并且在具有挑战性的场景下容易失败（例如，高速运动、多房间场景、纹理少或者没有纹理区域）。但是由于视觉SLAM相比与前者更加的经济实惠且能提供更加丰富的3D信息，所以具备被探索的潜力，也备受研究者们的追逐。 作者选择 基于密集光流的方法 （ dense optical ﬂow-based method （DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras. Advances in neural information processing systems）） 作为他工作的 baseline。随着计算能力的提高和深度学习研究的进步，这种基于光流的方法成为一种新的有前景的视觉SLAM范式。 在此之前，SLAM 方法主要分为基于关键点的方法（特征点法）和基于光度一致性的直接方法（光流法、直接法）。 根据每种方法的原理和特点，各有千秋。 一方面，基于关键点的方法更容易针对全局最优进行优化。 但是，它仅限于使用一小部分图像信息，而将其余可能有用的信息放在一边。 另一方面，直接方法使用半密集像素信息而不是仅使用稀疏关键点，但最小化光度一致性损失是一个更复杂的问题，在优化过程中更容易陷入局部最小值 。相比之下，基于密集光流的方法通过将密集像素信息的重投影误差作为稳定的优化目标，结合了基于关键点和直接基于光度计的方法的优点。 应用于移动机器人的 SLAM 方法经常结合来自车轮编码器的测量值，这是一种支持移动机器人导航的标准传感器。 根据地面材料的不同，车轮里程表可能会遇到不同程度的滑动，从而导致不同的水平测量误差。 长时间整合位姿，误差累积相当大。 相比之下，短时间内的位姿整合，更具体地说，在两个相邻关键帧的时间段内，是相当可靠的。 因此，为了增强整个系统的鲁棒性，车轮里程计的相对 2D 位姿变换被添加为连续关键帧之间的附加约束。 这些约束增加了轨迹估计的平滑度，并且在相机视图中缺少纹理时特别有用。 在室内环境中移动时，移动机器人需要依靠稠密的 3D 地图进行导航和避障。 作者使用深度相机来获取3D信息，因为现成的深度相机系统变得越来越可靠。 此外，深度相机在无纹理的室内场景中是有益的，因为它提供了用于对齐的几何信息。 简单地累积所有帧的深度点云将导致大量的信息冗余，因为相邻帧的观测结果大部分重叠。 为此，作者选择 TSDF 作为稠密 3D 地图的表示。这是一种基于体素的表示。 落入同一体素的 3D 点会被融合。 在减少冗余的同时，通过加权平均将观察噪声的影响降至最低。作者在特定时间窗口内构建分离的 TSDF 子图，这些子图可以在几何上相互对齐，为全局束调整（global BA）提供额外的约束。 结果，累积的姿势漂移可以通过闭合的长期循环来减轻。 与密集的光流约束相比，由于显着的视角和基线偏差可能会错过潜在的闭环，子图配准不受视角变化的限制，并且可以在几何上稳健地对齐地图。 a) 白墙前的摄像头跟踪失败； b) 与车轮里程计测量融合后的平滑跟踪；c) 因错过大基线回环闭合而被错位污染的重建地图； d) 改进了带有子图配准的密集地图。 作者还提出了一个深度图细化策略（depth map reﬁnement strategy），以提高密集重建的准确性和完整性。 观察误差相对于深度范围呈二次方增加。 在进行远距离观测时，深度测量会受到明显的观测噪声的影响，这会导致重建地图中出现大量重影和伪影，从而影响地图精度和机器人导航。 为了提高深度图质量，我们使用来自 SLAM 后端的全局 BA 的现成结果。 关键帧的优化深度图（在SLAM后端全局BA获得的深度图被成为优化深度图）受益于相邻帧之间光流的密集匹配，并且由于增加信息的联合优化而具有更高的精度。 根据 degree of over-determination，可以得出每个优化深度像素的置信度值$\\omega$，在此基础上优化深度（optimized depth）与原始传感器深度自适应融合。 此外，我们应用双边求解器来增强传感器深度图的平滑度，它利用彩色图像中的外观信息来保持物体边缘的清晰度，同时平滑物体表面上的测量值（这里的意思是深度相机直接获得的深度图成为原始传感器深度，这个深度图经过一个双边求解器来增强深度图的平滑度，这样就得到了一个平滑后的深度图，用这个平滑后的深度图与在SLAM后端全局BA获得的优化深度图进行一个自适应融合，得到最终的细化深度图，融合方案如下公式所示）。 从左到右：彩色图像、传感器深度图、平滑后深度图、优化的深度图和最终自适应融合后的深度图。有改进的地方和有所改善的区域用红色矩形标记 主要贡献总结 一种新颖的鲁棒室内视觉 SLAM 框架，通过探索不同约束的相互补充性质，克服了短期纹理缺失和长期大基线循环闭合的挑战。 一种基于传感器原始深度误差分析和结合颜色线索与双边求解器和全局束调整优化结果的深度图细化策略。 在多个数据集和数百个序列上进行实验，以验证所提出系统的有效性。 根据高端激光扫描仪模型评估最终重建。 ","date":"2022-07-15","objectID":"/towards-robust-indoor-vision-slam-and-dense-reconstruction-for-mobile-robots-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/:0:0","tags":["SLAM"],"title":"Towards Robust Indoor Vision SLAM and Dense Reconstruction for Mobile Robots 论文阅读","uri":"/towards-robust-indoor-vision-slam-and-dense-reconstruction-for-mobile-robots-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"categories":["CNN"],"content":"简介 介绍深度学习训练好的模型在C++中如何部署以及使用不同的推理引擎进行推理。这里是用Pytorch训练好的模型为例（用什么学习框架学习得到的模型没关系，都有对应的模块导出模型的）。PyTorch 模型经常需要部署在 C++ 程序中，目前我知道的方法有三种（还有其他方式我没有尝试过）： LibTorch: PyTorch 官方 C++ 库 ONNX Runtime OpenCV: DNN 模块 ","date":"2022-07-14","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/:1:0","tags":["CNN, ONNX Runtime"],"title":"深度学习模型的部署和推理","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/"},{"categories":["CNN"],"content":"ONNX Runtime ONNX Runtime 是一个跨平台推理和训练机器学习加速器。也就是说，训练好的模型导出为 ONNX 格式后，可以用 ONNX Runtime 进行推理。 ","date":"2022-07-14","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/:2:0","tags":["CNN, ONNX Runtime"],"title":"深度学习模型的部署和推理","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/"},{"categories":["CNN"],"content":"模型导出 ONNX（Open Neural Network Exchange）是一种针对机器学习所设计的开放式的文件格式，用于存储训练好的模型。它使得不同的人工智能框架（如Pytorch、MXNet）可以采用相同格式存储模型数据并交互。 ONNX的规范及代码主要由微软，亚马逊，Facebook和IBM等公司共同开发，以开放源代码的方式托管在Github上。目前官方支持加载ONNX模型并进行推理的深度学习框架有： Caffe2, PyTorch, MXNet，ML.NET，TensorRT 和 Microsoft CNTK，并且 TensorFlow 也非官方的支持ONNX。 使用torch.onnx.export 可以直接保存模型为 onnx 格式，实例代码如下： def export(model, inputL=None, inputR=None): import onnx device = torch.device('cpu') model = model.module.to(device) model.eval() if inputL is None: dummyL = torch.randn((1, 3, 368, 1232)).to(device) else: dummyL = inputL.to(device) if inputR is None: dummyR = torch.randn((1, 3, 368, 1232)).to(device) else: dummyR = inputR.to(device) onnx_path = \"anynet2.onnx\" # onnx_path = \"anynet_with_spn.onnx\" torch.onnx.export( model, (dummyL, dummyR), onnx_path, opset_version=11, input_names=[\"imgL\", \"imgR\"], output_names=[\"disp1\", \"disp2\", \"disp3\",] # output_names=[\"disp1\", \"disp2\", \"disp3\", \"disp4\"] ) onnx.checker.check_model(onnx.load(onnx_path)) print(\"ONNX model exported to: \" + onnx_path) ","date":"2022-07-14","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/:2:1","tags":["CNN, ONNX Runtime"],"title":"深度学习模型的部署和推理","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/"},{"categories":["CNN"],"content":"推理模型 如果使用 ONNX Runtime 进行推理的话，事先还需要安装 ONNX Runtime（使用Python 的话比较简单，使用C++的话略微复杂） ONNX Runtime 安装（C++） 安装的方式一般分从源码编译安装（可以参考这个，流程基本一致，MacOS源码编译onnxruntime）和使用预编译好的包 。 官网上的的Linux预编译包下载指引让人摸不着头脑，这里建议直接从Github Release页面下载。解压后你会发现预编译包里除了一些文档之外，只有头文件和二进制的库文件，没有任何包管理相关 (CMake、pkg-config 之类) 的配置文件。虽然源码 CMakeLists 中明明有 pkg-config 配置文件 .pc 的生成，但不知为何并没有被打包进预编译包。总之，拿到预编译包你没法直接通过 CMake/pkg-config 引入自己的工程。 所以，在 CMake 项目中无法通过 find_package 找到 ONNX Runtime。可以仿照这个仓库，使用 find_path 和 find_library 来查找： find_path(ONNX_RUNTIME_SESSION_INCLUDE_DIRS onnxruntime_cxx_api.h HINTS /usr/local/include/onnxruntime/core/session/) find_path(ONNX_RUNTIME_PROVIDERS_INCLUDE_DIRS cuda_provider_factory.h HINTS /usr/local/include/onnxruntime/core/providers/cuda/) find_library(ONNX_RUNTIME_LIB onnxruntime HINTS /usr/local/lib) add_executable(inference inference.cpp) target_include_directories(inference PRIVATE ${ONNX_RUNTIME_SESSION_INCLUDE_DIRS} ${ONNX_RUNTIME_PROVIDERS_INCLUDE_DIRS}) target_link_libraries(inference PRIVATE ${ONNX_RUNTIME_LIB}) 分别指定了包含路径、库路径、链接库。 或者也可以在预编译包的根目录下建立 share/cmake/onnxruntime 文件夹，在里面创建 onnxruntimeConfig.cmake 文件，内容为： #This will define the following variables: # onnxruntime_FOUND -- True if the system has the onnxruntime library # onnxruntime_INCLUDE_DIRS -- The include directories for onnxruntime # onnxruntime_LIBRARIES -- Libraries to link against # onnxruntime_CXX_FLAGS -- Additional (required) compiler flags include(FindPackageHandleStandardArgs) # Assume we are in \u003cinstall-prefix\u003e/share/cmake/onnxruntime/onnxruntimeConfig.cmake get_filename_component(CMAKE_CURRENT_LIST_DIR \"${CMAKE_CURRENT_LIST_FILE}\" PATH) get_filename_component(onnxruntime_INSTALL_PREFIX \"${CMAKE_CURRENT_LIST_DIR}/../../../\" ABSOLUTE) set(onnxruntime_INCLUDE_DIRS ${onnxruntime_INSTALL_PREFIX}/include) set(onnxruntime_LIBRARIES onnxruntime) set(onnxruntime_CXX_FLAGS \"\") # no flags needed find_library(onnxruntime_LIBRARY onnxruntime PATHS \"${onnxruntime_INSTALL_PREFIX}/lib\" ) add_library(onnxruntime SHARED IMPORTED) set_property(TARGET onnxruntime PROPERTY IMPORTED_LOCATION \"${onnxruntime_LIBRARY}\") set_property(TARGET onnxruntime PROPERTY INTERFACE_INCLUDE_DIRECTORIES \"${onnxruntime_INCLUDE_DIRS}\") set_property(TARGET onnxruntime PROPERTY INTERFACE_COMPILE_OPTIONS \"${onnxruntime_CXX_FLAGS}\") find_package_handle_standard_args(onnxruntime DEFAULT_MSG onnxruntime_LIBRARY onnxruntime_INCLUDE_DIRS) 然后将预编译包的 include、lib、share 三个文件夹拷到系统路径，或者注册用户包，就能在自己 CMake 项目中使用 find_package 找到 onnxruntime 了： # 增加opencv的依赖 FIND_PACKAGE( OpenCV REQUIRED ) # onnxruntime find_package( onnxruntime REQUIRED) include_directories(${onnxruntime_INCLUDE_DIRS}) ADD_EXECUTABLE( main main.cpp ) TARGET_LINK_LIBRARIES( main ${OpenCV_LIBS} ${onnxruntime_LIBRARIES} ) 使用 ONNX Runtime 推理 这里附上一段在C++中使用 ONNX Runtime 进行推理的代码。其中一定要注意进行推理之前，要进行正确的图像预处理。同时，推理得到的Tensor 之后，如需转换成其他格式，也需要进行合适的后处理。在我这段例子当中，是将模型推理得到的Tensor 转换成视差图也就是cv::Mat 格式 #include \u003calgorithm\u003e #include \u003cassert.h\u003e #include \u003ciostream\u003e #include \u003csstream\u003e #include \u003cvector\u003e #include \u003cstring\u003e #include \u003cpng.h\u003e #include \u003cexperimental_onnxruntime_cxx_api.h\u003e #include \u003connxruntime_c_api.h\u003e #include \u003cstdio.h\u003e #include \u003ctorch/torch.h\u003e #include \u003copencv2/dnn.hpp\u003e #include \u003copencv2/imgproc.hpp\u003e #include \u003copencv2/highgui.hpp\u003e using namespace std; using namespace cv; using namespace torch; // pretty prints a shape dimension vector std::string print_shape(const std::vector\u003cint64_t\u003e\u0026 v) { std::stringstream ss(\"\"); for (size_t i = 0; i \u003c v.size() - 1; i++) ss \u003c\u003c v[i] \u003c\u003c \"x\"; ss \u003c\u003c v[v.size() - 1]; return ss.str(); } // image pre-process Mat imagePreprocess(Mat sourceImg, Mat preprocessedImage, std::vector\u003cint64_t\u003e inputDims){ // step 1: Resize the image. cv::Mat resizedImageBGR, resizedImageRGB, resizedImage; cv::resize(sourceImg, resizedImageBGR, cv::Size(inputDims.at(3), inputDims.at(2)), cv::InterpolationFlags::INTER_CUBIC); // step 2: Convert the image to HWC RGB UINT8 format. cv::cvtColor(resizedImageBGR, resizedImageRGB, cv::ColorConversionCodes::COLOR_BGR2RGB); //","date":"2022-07-14","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/:2:2","tags":["CNN, ONNX Runtime"],"title":"深度学习模型的部署和推理","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/"},{"categories":["CNN"],"content":"OpenCV DNN 参见官方文档，OpenCV DNN 模块能够直接加载 onnx 格式的模型，使用这个模块可以直接进行推理。但是缺点是有一些网络中自定义的操作，可能不被opencv dnn模块所支持。实例代码如下： #include \u003copencv2/opencv.hpp\u003e using namespace cv; using namespace dnn; int main() { const bool use_cuda = false; const std::string fn_image = \"cat.jpg\"; const std::string fn_model = \"super_resolution.onnx\"; // load and config model Net net = readNetFromONNX(fn_model); net.setPreferableBackend(DNN_BACKEND_OPENCV); net.setPreferableTarget(DNN_TARGET_CPU); // source image auto image = imread(fn_image, cv::IMREAD_GRAYSCALE); Mat blob; blobFromImage(image, blob, 1.0 / 255.0); // inference and output net.setInput(blob); auto output = net.forward(); int new_size[] = { output.size[2], output.size[3] }; output = output.reshape(1, 2, new_size); convertScaleAbs(output, output, 255.0); } ","date":"2022-07-14","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/:3:0","tags":["CNN, ONNX Runtime"],"title":"深度学习模型的部署和推理","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/"},{"categories":["CNN"],"content":"Libtorch ","date":"2022-07-14","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/:4:0","tags":["CNN, ONNX Runtime"],"title":"深度学习模型的部署和推理","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/"},{"categories":["CNN"],"content":"模型导出 如果使用 LibTorch 进行推理的话，那么需要事先将模型导出为 Torch Script (.pt 格式) 文件，参见官方教程。有两种方法：Tracing 和 Scripting。 Tracing 就是提供一个示例输入，让 PyTorch 跑一遍整个网络，将过程中的全部操作记录下来，从而生成 Torch Script 模型： x = torch.randn(batch_size, 1, 224, 224, requires_grad=True) traced_script_model = torch.jit.trace(torch_model, x) traced_script_model.save(\"super_resolution.pt\") Scripting 则是直接分析网络结构转化模型： traced_script_model = torch.jit.script(torch_model) traced_script_model.save(\"super_resolution.pt\") 这两种方法各有优缺点：如果模型正向传播的控制流跟输入相关，显然 Tracing 只能得到一种输入下的控制流，此时应该用 Scripting；而当模型使用了一些 Torch Script 不支持的特性，同时模型源码又无法修改时（如果能访问源码，Scripting 可以通过加入注释的方法忽略它们），Scripting 便无能为力了，此时只能考虑 Tracing。更多关于 Tracing 和 Scripting 的区别可以参考 [Mastering TorchScript](https://paulbridger.com/posts/mastering-torchscript/)。 ","date":"2022-07-14","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/:4:1","tags":["CNN, ONNX Runtime"],"title":"深度学习模型的部署和推理","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/"},{"categories":["CNN"],"content":"推理部分 LibTorch 下载参见 PyTorch: Get Started。CMake 工程中使用 LibTorch 只需要加入 find_package(Torch REQUIRED)，并将自己的可执行文件/库链接到 ${TORCH_LIBRARIES} 即可。具体进行推理的 C++ 代码如下： #include \u003copencv2/opencv.hpp\u003e #include \u003ctorch/script.h\u003e torch::Tensor toTensor(const cv::Mat\u0026 image) { // convert 8UC1 image to 4-D float tensor CV_Assert(image.type() == CV_8UC1); return torch::from_blob(image.data, { 1, 1, image.rows, image.cols }, torch::kByte) .toType(torch::kFloat32) .mul(1.f / 255.f); } cv::Mat toMat(const torch::Tensor\u0026 tensor) { // convert tensor to 8UC1 image using namespace torch; Tensor t = tensor.mul(255.f).clip(0, 255).toType(kU8).to(kCPU).squeeze(); CV_Assert(t.sizes().size() == 2); return cv::Mat(t.size(0), t.size(1), CV_8UC1, t.data_ptr()).clone(); } int main() { const bool use_cuda = false; const std::string fn_image = \"cat.jpg\"; const std::string fn_model = \"super_resolution.pt\"; // load model auto module = torch::jit::load(fn_model); if (use_cuda) module.to(torch::kCUDA); // load source image auto image = imread(fn_image, cv::IMREAD_GRAYSCALE); auto input = toTensor(image); if (use_cuda) input = input.to(torch::kCUDA); // inference auto output = module.forward({ input }).toTensor(); auto result_torch = toMat(output); imwrite(\"result_torch.png\", result_torch); } 参考链接 pytorch模型部署 深度学习之从 python 到 C++ ","date":"2022-07-14","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/:4:2","tags":["CNN, ONNX Runtime"],"title":"深度学习模型的部署和推理","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%8E%A8%E7%90%86/"},{"categories":["opencv"],"content":"前言 传统的立体匹配算法当中，BM（Block Matching），SGBM（Semi-Global Block matching），是两种常用的算法。并且这两种算法都在opencv中已经有了良好的实现。算法速度上BM \u003e SGBM，匹配精度上：BM \u003c SGBM。 代码实例 #include \u003ciostream\u003e #include \u003copencv2/core.hpp\u003e #include \u003copencv2/opencv.hpp\u003e #include \u003copencv2/highgui.hpp\u003e #include \u003cchrono\u003e //for stereo matching #include\u003copencv2/calib3d.hpp\u003e //for point cloud visualization #include \u003cpcl/point_cloud.h\u003e #include \u003cpcl/visualization/cloud_viewer.h\u003e using namespace std; using namespace cv; int main(int argc, char **argv){ // load RGB images Mat imgL = imread(\"/home/codes/opencvTest/kittiTestImages/imgL/000000_10.png\", 1); Mat imgR = imread(\"/home/codes/opencvTest/kittiTestImages/imgR/000000_10.png\", 1); //keep left rgb image Mat rgb = Mat(imgL); // convert rgb images to grayscale cvtColor(imgL, imgL, CV_RGB2GRAY); cvtColor(imgR, imgR, CV_RGB2GRAY); int width = imgL.cols; int height = imgL.rows; // set parameters // 每个参数的意义和调整设计SGBM算法背后的原理，这里不做解释，可自行查阅 int minDisparity = 0; int numDisparities = 92; //max disparity - min disparity int blockSize = 9; int P1 = 8 * blockSize*blockSize; int P2 = 32 *blockSize*blockSize; int disp12MaxDiff = 1; int preFilterCap = 63; int uniquenessRatio = 10; int speckleWindowSize = 100; int speckleRange = 32; int mode = StereoSGBM::MODE_SGBM; //init stereoSGBM cv::Ptr\u003cStereoSGBM\u003e sgbm = StereoSGBM::create(minDisparity, numDisparities, blockSize, P1, P2, disp12MaxDiff, preFilterCap, uniquenessRatio, speckleWindowSize, speckleRange, mode); //computer disparity Mat imgDisparity16S = Mat(height, width, CV_16S); chrono::steady_clock::time_point startTime = chrono::steady_clock::now(); sgbm-\u003ecompute(imgL, imgR, imgDisparity16S); std::chrono::steady_clock::time_point endTime = std::chrono::steady_clock::now(); double computerDuration = chrono::duration_cast\u003cstd::chrono::duration\u003cdouble\u003e \u003e(endTime - startTime).count(); cout \u003c\u003c \"Time of computer disparity: \" \u003c\u003c computerDuration \u003c\u003c endl; //转换成32F格式获得真实视差值，这里记得缩放 Mat imgDisparity32F = Mat(height, width, CV_32F); imgDisparity16S.convertTo(imgDisparity32F, CV_32F, 1.0 / 16); //如果想看下获得的视差图效果 /* Mat imgDispMap8U = Mat(height, width, CV_8U); double max, min; Point minLoc, maxLoc; minMaxLoc(imgDisparity32F, \u0026min, \u0026max, \u0026maxLoc, \u0026minLoc); double alpha = 255.0 / (max - min); imgDisparity32F.convertTo(imgDispMap8U, CV_8U, alpha, -alpha * min); cv::Mat colorisedDispMap; cv::applyColorMap(imgDispMap8U, colorisedDispMap, cv::COLORMAP_JET); imshow(\"color_32F-8U\", colorisedDispMap); cv::waitKey(0); */ } 视差图可视化 通过SGBM算法获得的视差图效果如下，由于SGBM算法的参数众多，所以调整不同的参数或许有改善的空间，具体操作可自行查阅。 原双目图像rgb左图 通过SGBM算法立体匹配获得的视差图。 左边有一部分没有视差是正常的，那是右图中看不到的部分，这部分的宽窄与SGBM算法参数设置有关 进行空洞值插值处理 从视差图得到直观效果来说貌似还可以。但是在SLAM中，拥有视差图是为后面映射为点云做准备的，所以这里将2D视差图映射成3D点云看看效果 点云可视化 点云正面 点云侧面 正面看着效果勉强还行，但是实际上并不如此。缩放比例，同时旋转下方位，从侧面观察可以看出，其实估计点云模型存在着放射，发散等问题。原因是因为存在较多无效点，需要经过剔除处理。 附带代码 float fx = 718.856; float fy = 718.856; float cx = 607.1928; float cy = 185.2157; float baseline = 0.3861; pcl::PointCloud\u003cpcl::PointXYZRGB\u003e::Ptr pointcloud(new pcl::PointCloud\u003cpcl::PointXYZRGB\u003e); for (int v = 0; v \u003c imgL.rows; v++) { for (int u = 0; u \u003c imgL.cols; u++) { if (imgDisparity32F.at\u003cfloat\u003e(v, u) \u003c= 10 || imgDisparity32F.at\u003cfloat\u003e(v, u) \u003e= 96) continue; pcl::PointXYZRGB point; double x = (u - cx) / fx; double y = (v - cy) / fy; double depth = fx * baseline / (imgDisparity32F.at\u003cfloat\u003e(v, u)); point.x = x * depth; point.y = y * depth; point.z = depth; point.b = rgb.at\u003ccv::Vec3b\u003e(v, u)[0]; point.g = rgb.at\u003ccv::Vec3b\u003e(v, u)[1]; point.r = rgb.at\u003ccv::Vec3b\u003e(v, u)[2]; pointcloud-\u003epush_back(point); } } pcl::visualization::CloudViewer viewer(\"viewer\"); while(1){ viewer.showCloud(pointcloud); } void insertDepth32f(cv::Mat\u0026 depth) { const int width = depth.cols; const int height = depth.rows; float* data = (float*)depth.data; cv::Mat integralMap = cv::Mat::zeros(height, width, CV_64F); cv::Mat ptsMap = cv::Mat::zeros(height, width, CV_32S); double* integral = (double*)integralMap.data; int* ptsIntegral = (int*)ptsMap.data; memset(integral, 0, sizeof(double) * width * height); me","date":"2022-07-14","objectID":"/opencv-sgbm%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95/:0:0","tags":["SGBM"],"title":"Opencv SGBM立体匹配算法","uri":"/opencv-sgbm%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95/"},{"categories":["opencv"],"content":" 数据类型的形式 数据类型的形式一般为CV_\u003cbit_depth\u003e(S|U|F)C\u003cnumber_of_channels\u003e，其各自的含义如下： bit_depth：比特数，代表图像像素的位数，即像素深度，比如8bite、16bites、32bites、64bites S|U|F: S代表signed int 有符号整形。U代表 unsigned int 无符号整形。F代表 float 单精度浮点型 C\u003cnumber_of_channels\u003e: 代表一张图片的通道数比如: channels = 1：灰度图片。是单通道图像 channels = 3：RGB彩色图像。是3通道图像 channels = 4：带alpha通道的RGB图像，表示透明度。是4通道图像 例如：CV_8U 代表的是像素位数为8，无符号数据，单通道格式 常见Opencv的数据类型 cv类型 枚举数值 空间大小 范围 常规类型 CV_8U 0 8bits 0~255 unsigned char或uint8_t CV_8S 1 8bits -128~127 char或int8_t CV_16U 2 16bits 0~65535 ushort, unsigned short int, unsigned short或uint16_t CV_16S 3 16bits -32768~32767 short, short int或int16_t CV_32S 4 32bits -2147483648~2147483647 int,long或int32_t/int64_t CV_32F 5 32bits 1.18e-38~3.40e38 float CV_64F 6 64bits 2.23e-308~1.79e308 double 类型 C1 C2 C3 C4 CV_8U 0 8 16 24 CV_8S 1 9 17 25 CV_16U 2 10 18 26 CV_16S 3 11 19 27 CV_32S 4 12 20 28 CV_32F 5 13 21 29 CV_64F 6 14 22 30 Mat 的创建 常使用的是利用构造函数 Mat(nrows, ncols, type, [fillValue])，最后一个参数中括号里代表可选参数，表示填入的初始值，如果不写默认为0。nrows、ncols一般为int型的整数，但ncols也可以为数组，这样表示建立一个多维Mat,此时传入的nrows表示维度。前两个参数还可以用Size(ncol,nrow)代替(注意Size里行列的顺序和函数参数的顺序是反的)，这就是另一种构造函数了。 也可以先声明一个Mat，然后利用其成员函数创建Mat。create()成员函数格式如下：Mat(nrows,ncols,type)，它只能接收3个参数，与构造函数的区别就是无法赋初值。使用示例如下： cv::Mat m1(4, 3, CV_8UC1); cv::Mat m2(3, 5, CV_8UC1, 200); cv::Mat m4; m4.create(2, 3, CV_8UC1); Mat 常用属性和函数 rows：返回Mat的行数，仅对二维Mat有效，高维返回-1 cols：返回Mat的列数，仅对二维Mat有效，高维返回-1 size：返回Mat的尺寸大小(长x宽x高…) dims：返回Mat中数据的维度，OpenCV中维度永远大于等于2。如 3 * 4 的矩阵为 2 维， 3 * 4 * 5 的为3维 depth()：用来度量每一个像素中每一个通道的精度，但它本身与图像的通道数无关！depth数值越大，精度越高。在Opencv中，Mat.depth()得到的是一个0~6的数字，分别代表不同的位数，对应关系如下： enum{CV_8U=0,CV_8S=1,CV_16U=2,CV_16S=3,CV_32S=4,CV_32F=5,CV_64F=6} channels()：通道数量，矩阵中表示一个元素所需要的值的个数。Mat矩阵元素拥有的通道数。例如常见的RGB彩色图像，channels==3；而灰度图像只有一个灰度分量信息，channels==1。 at()：返回Mat某行某列的元素(可修改) tr()：返回指向Mat的行指针 clone()：返回Mat的深拷贝 copyTo()：返回Mat的深拷贝 eye()：生成单位阵 zeros()：生成元素全为0的矩阵 ones()：生成元素全为1的矩阵 type()：返回Mat的元素类型索引 inv()：Mat求逆 mul()：Mat矩阵乘法 data()：返回指向矩阵数据单元的指针 total()：返回矩阵中的元素总数 cv::hconcat()：水平拼接两个矩阵 cv::vconcat()：数值拼接两个矩阵 Mat的元素操作 获取Mat中的元素可以使用成员函数 at()。.at\u003c\u003e() 用法是尖括号\u003c\u003e传入模板参数，表示数据类型，小括号()中再传入行、列的索引，返回元素的引用。也可以只传入行或列，这样就是整行或者整列。at()函数传入的模板参数数据类型必须与Mat的数据类型严格一致。 cv::Mat m1 = cv::Mat::eye(3, 3, CV_32F); m1.at\u003cfloat\u003e(1,1) = 2.0; 也可以使用ptr()成员函数。它返回的是一个指针。 Mat M = Mat::eye(10, 10, CV_64F); double sum = 0; for (int i = 0; i \u003c M.rows; i++) { const double *Mi = M.ptr\u003cdouble\u003e(i); for (int j = 0; j \u003c M.cols; j++) sum += std::max(Mi[j], 0.); } 图像的显示 imshow函数在显示图像时，会将各种类型的数据都映射到[0, 255]。 比如：如果载入的图像是8U类型，就显示图像本来的样子。如果图像是16U 或32S（32S去掉符号位只有16位），便用像素值除以256。也就是说，值的范围是 [0, 255*256]映射到[0,255]。如果图像是32位或64位浮点型（32For 64F），像素值便要乘以255。也就是说，该值的范围是 [0,1]映射到[0,255]。 如：CV_8U的灰度或BGR图像的颜色分量都在0~255之间。直接imshow可以显示图像。CV_32F或者CV_64F取值范围为0~1.0，imshow的时候会把图像乘以255后再显示。 图像的尺寸操作 #include \u003copencv2/opencv.hpp\u003e #include \u003copencv2/imgproc/imgproc.hpp\u003e using namespace cv; int main() { Mat srcImage = imread(\"1.jpg\"); Mat temImage, dstImage1, dstImage2; temImage = srcImage; //尺寸调整 //第一个参数：输入图像 //第二个参数：输出图像 //第三个参数输出图像的尺寸，如果是0，则有dsize=Size(round(fx*src.cols),round(fy*src,rows))计算得出 //第四个参数：水平轴的缩放系数，默认为0 //第五个参数：y轴撒谎能够的缩放系数，默认为0 //第六个参数：插值方式，默认为INTER_LINEAR线性插值 resize(temImage, dstImage1, Size(temImage.cols / 2, temImage.rows / 2), 0, 0, INTER_LINEAR); resize(temImage, dstImage2, Size(temImage.cols * 2, temImage.rows * 2), 0, 0, INTER_LINEAR); imshow(\"缩小\", dstImage1); imshow(\"放大\", dstImage2); waitKey(); return 0; 图像标准化操作(减去均值，除以方差) cv::Mat Normalizer(cv::Mat src, cv::Mat dst){ std::vector\u003cfloat\u003e mean = {0.485, 0.456, 0.406}; std::vector\u003cfloat\u003e std = {0.229, 0.224, 0.225}; std::vector\u003ccv::Mat\u003e bgrChannels(3); cv::split(src, bgrChannels); for (auto i = 0; i \u003c bgrChannels.size(); i++) { bgrChannels[i].convertTo(bgrChannels[i], CV_32FC1, 1.0 / std_value[i], (0.0 - mean_value[i]) / std_value[i]); } cv::meger(bgrChannels, dst); } 数据类型之间的转换 void convertTo( OutputArray m, int rtype, double alpha=1, double beta=0 ) const; 描述：把一个矩阵从一种数据类型转换到另一种数据类型，同时可以带上缩放因子和增量。 参数解释 m 目标矩阵。如果m在运算前没有合适的尺寸或类型，将被重新分配。 rtype 目标矩阵的类型。因为目标矩阵的通道数与源矩阵一样，所以r","date":"2022-07-14","objectID":"/opencv%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:0:0","tags":["cv::Mat"],"title":"Opencv图像数据类型","uri":"/opencv%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["opencv"],"content":"介绍 归一化和标准化都是对数据做变换，将原始的一组数据转换到某个范围或者说到某种状态。在数据处理的时候我们常会碰到如下三种处理： 归一化（Normalization）：将一组数据变化到某个固定区间内，比较常见的如[0, 1]。广义来说可以是各种区间，比如在对图像进行处理是会经常映射到[0, 255]，也有映射到[-1, 1]的情况 标准化（Standardization）：将一组数据变换为均值为0，标准差为1的分布（该分布并非一定符合正态分布） 中心化：中心化也叫零均值处理，就是用一组原始数据减去这些数据的均值。比如在ICP算法中会先对数据进行中心化 联系和区别 本质上，归一化和标准化都是对数据做线性变换。 但是也存在一些区别。比如第一，归一化会严格的限定变换后数据的区间。而标准化没有严格的区间限定，只是其数据的均值为0，标准差为1。第二，归一化对数据的缩放比例仅仅和极值有关，比如100个数，你除去极大值和极小值其他数据都更换掉，缩放比例$\\alpha = X_{max}-X_{min}$是不变的；但是标准化中，如果除去极大值和极小值其他数据都更换掉，那么均值和标准差大概率会改变，这时候，缩放比例自然也改变了。 标准化和归一化的多种形式 广义的说，标准化和归一化同为对数据的线性变化，所以我们没必要规定死，归一化就是必须到[ 0 , 1]之间，我到[ 0 , 1 ]之间之后再乘一个255也没有问题对吧。常见的有以下几种： 归一化的最通用模式Normalization，也称线性归一化： $$X_{n e w}=\\frac{X_{i}-X_{\\min }}{X_{\\max }-X_{\\min }}, \\text { 范围 }[0,1]$$ 均值归一化 （Mean normalization）： $$X_{n e w}=\\frac{X_{i}-\\operatorname{mean}(X)}{X_{\\text {max }}-X_{\\min }} \\text {, 范围 }[-1,1]$$ 标准化(Standardization)，也叫标准差标准化： $$X_{n e w}=\\frac{X_{i}-\\mu}{\\sigma} \\text {, 范围实数集 }$$ 标准化、归一化的原因、用途 为何统计模型、机器学习和深度学习任务中经常涉及到数据(特征)的标准化和归一化呢，一半原因以下几点，当然可能还有一些其他的作用，大家见解不同，我说的这些是通常情况下的原因和用途。 统计建模中，如回归模型，自变量X 的量纲不一致导致了回归系数无法直接解读或者错误解读；需要将X都处理到统一量纲下，这样才可比； 机器学习任务和统计学任务中有很多地方要用到“距离”的计算，比如PCA，比如KNN，比如kmeans等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果； 参数估计时使用梯度下降，在使用梯度下降的方法求解最优化问题时， 归一化/标准化后可以加快梯度下降的求解速度，即提升模型的收敛速度。 什么时候Standardization，什么时候Normalization 如果对输出结果范围有要求，用归一化 如果数据较为稳定，不存在极端的最大最小值，用归一化 如果数据存在异常值和较多噪音，用标准化，可以间接通过中心化避免异常值和极端值的影响 cv::normalize() 函数介绍 void normalize(InputArray src, OutputArray dst, double alpha=1, double beta=0, int norm_type=NORM_L2, int dtype=-1, InputArray mask=noArray()); 参数 src - 输入数组 dst - 输出数组，支持原地运算 alpha - range normalization模式的最小值 beta - range normalization模式的最大值，不用于norm normalization(范数归一化)模式。 norm_type - 归一化的类型，可以有以下的取值 NORM_MINMAX:数组的数值被平移或缩放到一个指定的范围，线性归一化，一般较常用。比如归一化到[min, max]范围内，则计算公式如下： $$d s t(i, j)=\\frac{[\\operatorname{src}(i, j)-\\min (\\operatorname{src}(x, y))] *(\\max -\\min )}{\\max (\\operatorname{src}(x, y))-\\min (\\operatorname{src}(x, y))}+\\min$$ NORM_INF: 归一化数组的无穷范数(绝对值的最大值)。每个值除以最大值来进行无穷范数归一化。同上最终归一化的值为单位向量的每个值乘以参数要归一化的范数值alpha NORM_L1 : 归一化数组的L1-范数(绝对值的和)。数组元素绝对值求和，然后算出每一个元素比上总和的比值，加起来总为1。这里要归一化的范数值为1.0，所求出的比值即为最后归一化后的值，若归一化范数值alpha为2.0，则每个比值分别乘以2.0即得到最后归一化后的结果为0.2, 0.8, 1.0，以此类推 NORM_L2: 归一化数组的L2-范数(各元素的平方和然后求平方根 ，欧氏距离)。即将该向量归一化为单位向量，每个元素值除以该向量的模长。同上最终归一化的值为单位向量的每个值乘以参数要归一化的范数值alpha dtype - 为负值时, 输出数据类型和输入数据类型一致，否则和src通道一致，depth =CV_MAT_DEPTH(dtype) mask - 掩码。选择感兴趣区域，选定后只能对该区域进行操作。 参考链接 标准化和归一化，请勿混为一谈，透彻理解数据变换 ","date":"2022-07-14","objectID":"/opencv%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8C%E5%BD%92%E4%B8%80%E5%8C%96/:0:0","tags":["opencv"],"title":"Opencv数据标准化和归一化","uri":"/opencv%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8C%E5%BD%92%E4%B8%80%E5%8C%96/"},{"categories":["软件安装"],"content":"介绍 Git 是目前世界上被最广泛使用的现代软件版本管理系统。Git 本身亦是一个成熟并处于活跃开发状态的开源项目，它最初是由 Linux 操作系统内核的创造者 Linus Torvalds 在 2005 年创造。今天惊人数量的软件项目依赖 Git 进行版本管理，这些项目包括开源以及各种商业软件。Git 在职业软件开发者中拥有良好的声誉，Git 目前支持绝大多数的操作系统以及 IDE（Integrated Development Environments）。 快速指南 该快速指南是面向从零开始的读者。 ","date":"2022-07-14","objectID":"/git%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E4%BB%A5%E5%8F%8Avscode%E5%8F%AF%E8%A7%86%E5%8C%96git/:0:0","tags":["Git"],"title":"Git快速入门以及VScode可视化Git","uri":"/git%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E4%BB%A5%E5%8F%8Avscode%E5%8F%AF%E8%A7%86%E5%8C%96git/"},{"categories":["软件安装"],"content":"安装Git Linux ： sudo apt-get install git Git 的高质量中文教程 https://github.com/geeeeeeeeek/git-recipes.git vs code上 Git可视化教程 https://cloud.tencent.com/developer/article/1793472 ","date":"2022-07-14","objectID":"/git%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E4%BB%A5%E5%8F%8Avscode%E5%8F%AF%E8%A7%86%E5%8C%96git/:1:0","tags":["Git"],"title":"Git快速入门以及VScode可视化Git","uri":"/git%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E4%BB%A5%E5%8F%8Avscode%E5%8F%AF%E8%A7%86%E5%8C%96git/"},{"categories":["软件安装"],"content":"前言 pcl库的编译安装真心让人想吐，运气好一次通过，运气不好（各种环境的、各种依赖的问题）两三天就过去了。在这里分享下我安装pcl所遇到的问题。 通过sudo apt 安装 通过这种方式安装的最大的好处就是简单且不容易出现编译安装的问题，缺点就是可能会有部分功能无法使用 ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:0:0","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"安装依赖 sudo apt-get update sudo apt-get install git build-essential linux-libc-dev sudo apt-get install cmake cmake-gui sudo apt-get install libusb-1.0-0-dev libusb-dev libudev-dev sudo apt-get install mpi-default-dev openmpi-bin openmpi-common sudo apt-get install libflann1.9 libflann-dev sudo apt-get install libeigen3-dev sudo apt-get install libboost-all-dev sudo apt-get install libqhull* libgtest-dev sudo apt-get install freeglut3-dev pkg-config sudo apt-get install libxmu-dev libxi-dev sudo apt-get install mono-complete sudo apt-get install libopenni-dev sudo apt-get install libopenni2-dev sudo apt-get install libvtk7-dev libvtk6-dev sudo apt-get install qt5-default ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:1:0","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"安装PCL sudo apt-get install libpcl-dev 至此，PCL库的安装和配置就算是完成了，接下来测试一下PCL库是否可以正常运行 ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:2:0","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"测试 ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:3:0","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"编写源文件 写个测试用的源文件 test.cpp （网上copy的） #include \u003ciostream\u003e #include \u003cpcl/common/common_headers.h\u003e #include \u003cpcl/io/pcd_io.h\u003e #include \u003cpcl/visualization/pcl_visualizer.h\u003e #include \u003cpcl/visualization/cloud_viewer.h\u003e #include \u003cpcl/console/parse.h\u003e int main(int argc, char **argv) { std::cout \u003c\u003c \"Test PCL !!!\" \u003c\u003c std::endl; pcl::PointCloud\u003cpcl::PointXYZRGB\u003e::Ptr point_cloud_ptr (new pcl::PointCloud\u003cpcl::PointXYZRGB\u003e); uint8_t r(255), g(15), b(15); for (float z(-1.0); z \u003c= 1.0; z += 0.05) { for (float angle(0.0); angle \u003c= 360.0; angle += 5.0) { pcl::PointXYZRGB point; point.x = 0.5 * cosf (pcl::deg2rad(angle)); point.y = sinf (pcl::deg2rad(angle)); point.z = z; uint32_t rgb = (static_cast\u003cuint32_t\u003e(r) \u003c\u003c 16 | static_cast\u003cuint32_t\u003e(g) \u003c\u003c 8 | static_cast\u003cuint32_t\u003e(b)); point.rgb = *reinterpret_cast\u003cfloat*\u003e(\u0026rgb); point_cloud_ptr-\u003epoints.push_back (point); } if (z \u003c 0.0) { r -= 12; g += 12; } else { g -= 12; b += 12; } } point_cloud_ptr-\u003ewidth = (int) point_cloud_ptr-\u003epoints.size (); point_cloud_ptr-\u003eheight = 1; pcl::visualization::CloudViewer viewer (\"test\"); viewer.showCloud(point_cloud_ptr); while (!viewer.wasStopped()){ }; return 0; } ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:3:1","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"编写CMakeLists.txt 在目录下创建TestPCL文件夹，用于存储测试项目的文件，将test.cpp和CMakeLists.txt存储至TestPCL文件夹，创建TestPCL/bulid文件夹以储存中间文件。 cmake_minimum_required(VERSION 2.6) project(TEST) find_package(PCL REQUIRED) include_directories(${PCL_INCLUDE_DIRS}) link_directories(${PCL_LIBRARY_DIRS}) add_definitions(${PCL_DEFINITIONS}) add_executable(TEST test.cpp) target_link_libraries (TEST ${PCL_LIBRARIES}) install(TARGETS TEST RUNTIME DESTINATION bin) ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:3:2","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"编译安装运行 cd build cmake .. make ./TEST ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:3:3","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"正常运行结果 通过源码安装 ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:3:4","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"安装PCL依赖 sudo apt-get update sudo apt-get install git build-essential linux-libc-dev sudo apt-get install cmake cmake-gui sudo apt-get install libusb-1.0-0-dev libusb-dev libudev-dev sudo apt-get install mpi-default-dev openmpi-bin openmpi-common sudo apt-get install libflann1.9 libflann-dev # 有说ubuntu16对应1.8，ubuntu18对应1.9，我直接用了1.9 sudo apt-get install libeigen3-dev sudo apt-get install libboost-all-dev sudo apt-get install libqhull* libgtest-dev sudo apt-get install freeglut3-dev pkg-config sudo apt-get install libxmu-dev libxi-dev sudo apt-get install mono-complete sudo apt-get install libopenni-dev sudo apt-get install libopenni2-dev ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:4:0","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"安装VTK ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:5:0","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"安装vtk依赖 #首先安装VTK的依赖：X11，OpenGL；cmake和cmake-gui在安装pcl依赖的时候安装过了的话可以跳过 sudo apt-get install libx11-dev libxext-dev libxtst-dev libxrender-dev libxmu-dev libxmuu-dev #OpenGL sudo apt-get install build-essential libgl1-mesa-dev libglu1-mesa-dev #cmake \u0026\u0026 cmake-gui sudo apt-get install cmake cmake-gui ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:5:1","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"下载vtk 官网下载链接：Download | VTK 这里要注意以下VTK 和 PCL 版本之间的兼容性。我不确切肯定有版本兼容的问题，只是在我尝试了不同VTK版本后，发现VTK版本和PCL的版本还是有一定要求的。最好安装两者的版本如下（自己尝试过）: ubuntu版本呢 pcl 版本 vtk版本 18.04 / 20.04 1.9.1 8.2.0 18.04 / 20.04 1.8.1 7.1.1 16.04 1.7.2 5.10.1 /6.2.0 ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:5:2","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"编译安装 下载完成之后解压到准备好的安装目录，再通过终端打开 cmake GUI 模式 cmake-gui 在cmake-gui中： 配置 where is the source code 为VTK-8.2.0所在目录。（然后在VTK-8.2.0所在目录下新建一个build文件夹） 配置 where to build the binaries 为VTK-8.2.0下的build文件夹 点击Configure，（用“Unix Makefiles”就可以）。配置完成后，显示“Configuring done” 勾选VTK-Group-Qt，VTK_QT_VERSION选为5，再点击Configure，配置完成后，显示“Configuring done” 点击Generate，显示“Generating done”，在build文件夹下生成工程文件 推出cmake-gui 在终端里切换到VTK-8.2.0安装目录下的build文件夹 make -j4 #性能好内存大的电脑就用 -j8 吧 sudo make install ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:5:3","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"安装PCL 官网下载连接：Releases · PointCloudLibrary/pcl 到PCL的github主页下载需要的版本(这里我下载的1.9.1)，放到准备好的安装目录下。打开终端，进到pcl的安装目录下： mkdir build cd build # 设置CMAKE_INSTALL_PREFIX是为了把pcl安装到指定文件夹内，所以这个路径根据自己的情况设置 cmake -DCMAKE_INSTALL_PREFIX=/usr/local/pcl-1.9.1 -DCMAKE_TYPE=None .. make -j4 #一样的，根据实际情况调整 sudo make install ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:6:0","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"测试 同上 ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:7:0","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"遇到的问题 ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:8:0","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"问题1 在make pcl的时候，报错：“/usr/bin/ld: cannot find -lvtkIOMPIImage /usr/bin/ld: cannot find -lvtkIOMPIParallel /usr/bin/ld: cannot find -lvtkFiltersParallelDIY2” 解决方案 重新编译安装 vtk。在cmake-gui模式下，完成第3步的Configure，然后勾选Advanced，在search中把/usr/bin/ld找不到的vtkIOMPIImage，vtkIOMPIParallel，vtkFiltersParallelDIY2都选上。包括如果出现了类似的问题也可以县看看这里面是否可以选上的。 再点击Configure，显示“Configuring done”，点击Generate，显示“Generating done”。 打开终端，完成 make 和 sudo make install ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:8:1","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"问题2 cmake pcl 的时候，提示Checking for module ‘metslib’ – No package ‘metslib’ found 解决方案 安装metslib（我用的是0.5.3版本） 下载链接：https://www.coin-or.org/download/source/metslib/metslib-0.5.3.tgz 解压后，在metslib-0.53打开命令终端并执行 sudo sh ./configure sudo make sudo make install 顺利完成安装metslib ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:8:2","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"问题3 No rule to make target in /usr/lib/x86_64-linux-gnu/libpcl_surface. so **后面的内容不记得了** 解决方案 lcoate libpcl_surface. so /usr/lib/x86_64-linux-gnu/libpcl_surface.so.1.10 结果没有上面说的libpcl_surface. so，这是因为我之前通过sudo apt install libpcl-dev 安装过pcl，所以动态库还保留在那里。 简而言之就是，要在/usr/lib/x86_64-linux-gnu/ 找libpcl_surface. so这个动态库。 所以先找到 libpcl_surface. so在哪里 whereis libpcl_surface. so libpcl_surface: /usr/lib/libpcl_surface.so 发现在/usr/lib/这个路径。所以只需要把这个路径下的动态库建立一个软链接到/usr/lib/x86_64-linux-gnu/就行。大概了，还有很多动态库都是这种情况，所以可以使用候补符号一次性解决。 sudo ln -s /usr/lib/libpcl_*.so /usr/lib/x86_64-linux-gnu 参考链接 二、PLC安装踩坑总结（Ubuntu 16.4+PCL1.8.1+VTK7.1+Qt5.9.9)_way7486chundan的博客-CSDN博客 ","date":"2022-07-14","objectID":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/:8:3","tags":["PCL"],"title":"Ubuntu20.04安装PCL库","uri":"/pcl%E5%BA%93%E5%9C%A8ubuntu20.04%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":["软件安装"],"content":"简介 Latex是一个基于TEX的排班系统。粘贴复制的话就不搞了。简而言之，通俗来说，就是用来写文章的，而且完全不需要你去花时间去自己考虑排版、页码等没必要花时间去弄的玩意。而且，对于数学公式的输入也是极为方便，这点在后面会展示。 安装 安装发行版 sudo apt-get install texlive-full 安装XeLaTeX编译引擎sudo apt-get install texlive-xetex 安装中文支持包（如果需要）sudo apt-get install texlive-lang-chinese 安装编辑器（图形化界面的选择有很多，例如 TeXStudio，TeXmaker等，可以看做是一个编辑器，这里安装的是TexStudio）sudo apt-get install texstudio 配置 设置编译器为XeLaTeX，TeXstudio中在Options-\u003eConfigure TeXstudio-\u003eBuild-\u003eDefault Compiler中更改默认编译器为XeLaTeX 更改软件界面语言，将Options-\u003eConfigure TeXstudio-\u003eGeneral-\u003eLanguage改为zh-CN即可将界面设置为中文 其他工具和资源 ","date":"2022-06-30","objectID":"/ubuntu20.04%E5%AE%89%E8%A3%85latex%E5%B9%B6%E9%85%8D%E7%BD%AE%E4%B8%AD%E6%96%87%E7%8E%AF%E5%A2%83/:0:0","tags":["Latex"],"title":"Ubuntu20.04安装LaTeX并配置中文环境","uri":"/ubuntu20.04%E5%AE%89%E8%A3%85latex%E5%B9%B6%E9%85%8D%E7%BD%AE%E4%B8%AD%E6%96%87%E7%8E%AF%E5%A2%83/"},{"categories":["软件安装"],"content":"Mathpix 在写论文或者文档的时候，经常会碰到要输入数学公式的情况。如果去手敲，效率很低。这里介绍一个数学公式的latex语句生成工具 Mathpix。 碰到文献里的数学公式，只需要用这个软件，就可以轻松获得这个公式的latex语句。 ","date":"2022-06-30","objectID":"/ubuntu20.04%E5%AE%89%E8%A3%85latex%E5%B9%B6%E9%85%8D%E7%BD%AE%E4%B8%AD%E6%96%87%E7%8E%AF%E5%A2%83/:0:1","tags":["Latex"],"title":"Ubuntu20.04安装LaTeX并配置中文环境","uri":"/ubuntu20.04%E5%AE%89%E8%A3%85latex%E5%B9%B6%E9%85%8D%E7%BD%AE%E4%B8%AD%E6%96%87%E7%8E%AF%E5%A2%83/"},{"categories":["软件安装"],"content":"模板 模板这里分享一个latex模板网站 模板 ","date":"2022-06-30","objectID":"/ubuntu20.04%E5%AE%89%E8%A3%85latex%E5%B9%B6%E9%85%8D%E7%BD%AE%E4%B8%AD%E6%96%87%E7%8E%AF%E5%A2%83/:0:2","tags":["Latex"],"title":"Ubuntu20.04安装LaTeX并配置中文环境","uri":"/ubuntu20.04%E5%AE%89%E8%A3%85latex%E5%B9%B6%E9%85%8D%E7%BD%AE%E4%B8%AD%E6%96%87%E7%8E%AF%E5%A2%83/"},{"categories":["软件安装"],"content":"APT软件包管理系统 apt-get install apt一般直接安装已经编译好的可执行文件，会直接帮你处理依赖关系，apt-get install安装目录是包的维护者确定的，不是用户。系统安装软件一般在/usr/share，可执行的文件在/usr/bin，配置文件可能安装到了/etc下等。 apt-get remove 卸载已安装的软件包（保留配置文件） apt-get remove -purge 卸载已安装的软件包同时删除配置文件 apt-get autoremove 删除为了满足其他软件包的依赖而安装的，但现在不再需要的软件包(新手注意在桌面版的Ubuntu系统下尽量不要使用) apt-get update 更新软件信息数据库 apt-get upgrade 进行系统升级，即更新已安装的包 apt-get autoclean如果你的硬盘空间不大的话，可以定期运行这个程序，将已经删除了的软件包的.deb安装文件从硬盘中删除掉。如果你仍然需要硬盘空间的话，可以试试apt-get clean，这会把你已安装的软件包的安装包也删除掉，当然多数情况下这些包没什么用了，因此这是个为硬盘腾地方的好办法。 apt-get clean 类似上面的命令，但它删除包缓存中的所有包。这是个很好的做法，因为多数情况下这些包没有用了。但如果你是拨号上网的话，就得重新考虑了。 源码 这种软件包里面都是源程序，没有编译过，经过编译后才能安装。源码安装大致可以分为三步:（./configure）–＞ 编译（sudo make） –＞ 安装（sudo make install） 配置：这是编译源代码的第一步，通过 ./configure 命令完成。执行此步以便为编译源代码作准备。常用的选项有 --prefix=PREFIX，用以指定程序的安装位置。更多的选项可通过 --help 查询。也有某些程序无需执行此步。如果配置了–prefix，如：./configure --prefix=/usr/local/test安装后的所有资源文件都会被放在/usr/local/test目录中，不会分散到其他目录。 编译：一旦配置通过，可即刻使用 make 指令来执行源代码的编译过程。视软件的具体情况而定，编译所需的时间也各有差异，我们所要做的就是耐心等候和静观其变。此步虽然仅下简单的指令，但有时候所遇到的问题却十分复杂。较常碰到的情形是程序编译到中途却无法圆满结束。此时，需要根据出错提示分析以便找到应对之策。 安装：如果编译没有问题，那么执行 sudo make install 就可以将程序安装到系统中了。 当某个安装的软件不再需要时，只须简单的删除该安装目录，就可以把软件卸载干净；移植软件只需拷贝整个目录到另外一个机器即可（相同的操作系统下）当然要卸载程序，也可以在原来的make目录下用一次make uninstall，但前提是Makefile文件有uninstall命令。 如果没有配置--prefix选项，源码包也没有提供make uninstall，则可以通过以下方式可以完整卸载：设置一个临时目录重新安装一遍，如： ./configure --prefix=/tmp/to_remove \u0026\u0026makeinstall然后遍历/tmp/to_remove的文件，删除对应安装位置的文件即可（因为/tmp/to_remove里的目录结构就是没有配置--prefix选项时的目录结构） locate 找到要卸载的软件的安装位置，然后删除所有对应的文件。例如： sudo rm -r /usr/local/include/vtk-8.2 /usr/local/lib/cmake/vtk-8.2/ /usr/local/share/doc/vtk-8.2 DPKG Ubuntu系统中，软件通常以.deb格式的包文件发布，它是一种预编译软件包。deb包中除了包含已编译的软件，通常还包括软件的拷贝路径、对其他软件包的依赖关系记录、一个比较通用的配置文件以及软件的描述、版本、作者、类别、占用空间等信息。针对dpkg来说，它只能安装一个.deb格式的包，同时会通知你安装这个包需要什么样的依赖，但是不会安装那些依赖文件，同时也对这个包进行配置，因为那些依赖包并没有下载安装。 deb软件包命令遵行如下约定： **soft_ver_rev_arch.deb**soft为软件包名，ver为版本号，rev为Ubuntu修订版本号，arch为目标架构名称 dpkg -i | --install xxx.deb 安装deb安装包 dpkg -r | --remove xxx.deb 删除安装包 dpkg -r -p |--purge xxx.deb 连同配置文件一起删除 dpkg -I | -info xxx.deb 产看软件包信息 dpkg -L xxx.deb 查看文件拷贝信息 dpkg -l 查看系统中以安装软件包信息 dpkg-reconfigure xxx 重新配置软件包 有些时候，使用dpkg安装一个软件包，系统会提示该软件包依赖其他软件包。这时，需要先安装其他软件包，知道满足依赖关系为止。或者同时安装多个软件包，如：dpkg -i aaa.deb bbb.deb ccc.deb 。但是，如果一个软件依赖关系过于复杂，使用\"dpkg\"来安装它，并不是一个明智的选择，这个时候需要用到APT软件包管理系统。APT可以自动的检查依赖关系，通过预设的方法来获得相关软件包，并自动安装配置它。事实上，在多数情况下，我们推荐使用APT软件包管理系统。 ","date":"2022-06-30","objectID":"/ubuntu%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:0:0","tags":["Linux"],"title":"Ubuntu安装卸载基础知识","uri":"/ubuntu%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]