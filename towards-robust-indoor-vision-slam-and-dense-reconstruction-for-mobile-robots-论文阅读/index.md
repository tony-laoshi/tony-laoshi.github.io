# Towards Robust Indoor Vision SLAM and Dense Reconstruction for Mobile Robots 论文阅读



# 相关链接
标题：Towards Robust Indoor Vision SLAM and Dense Reconstruction for Mobile Robots  
作者：Zhang, W; Wang, S; Haala, N.   
来源：ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences; Gottingen Vol. V-1-2022,  (2022): 211-219.  
DOI：10.5194/isprs-annals-V-1-2022-211-2022

# 动机
当前视觉SLAM可以很好的构建各种室内场景，但大多应用于室内小空间，且通常在纹理良好的环境中。 在大型室内场景的实际应用中，它们缺乏鲁棒性，无法构建全局一致的地图。 为此，在这篇文章中作者提出了一种新颖的系统，可以稳健地解决现有视觉 SLAM 遇到的问题，例如弱纹理和长期漂移。  
<br/>
<br/>

# 整体思路

- 通过结合来自车轮里程计的信息，可以在没有纹理的情况下平滑地预测机器人位姿。 
- 通过对齐基于截断有符号距离函数 (TSDF) 的子图来利用几何线索，以最大限度地减少长期漂移。 
- 为了重建更完整和准确的稠密图，利用颜色信息和全局束调整（global BA）的优化结果来细化传感器获得的深度图。
<br/>
<br/>

# 结果
在公共数据集和自收集数据集上验证了所提出方法的准确性和鲁棒性，并展示了每个模块的互补性。 基于高精度ground-truth的评估结果表明，轨迹估计的平均绝对轨迹误差（ATE）从21 cm提高到2 cm，重建地图的平均精度为8 cm。
<br/>
<br/>


# 介绍
在目前阶段激光SLAM表现出强大的性能，视觉SLAM相比较之下缺乏足够的鲁棒性，并且在具有挑战性的场景下容易失败（例如，高速运动、多房间场景、纹理少或者没有纹理区域）。但是由于视觉SLAM相比与前者更加的经济实惠且能提供更加丰富的3D信息，所以具备被探索的潜力，也备受研究者们的追逐。  
<br/>

作者选择 基于密集光流的方法 （ dense optical ﬂow-based method （DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras. Advances in neural information processing systems）） 作为他工作的 baseline。随着计算能力的提高和深度学习研究的进步，这种基于光流的方法成为一种新的有前景的视觉SLAM范式。
<br/>

在此之前，SLAM 方法主要分为基于关键点的方法（特征点法）和基于光度一致性的直接方法（光流法、直接法）。 根据每种方法的原理和特点，各有千秋。 一方面，基于关键点的方法更容易针对全局最优进行优化。 但是，它仅限于使用一小部分图像信息，而将其余可能有用的信息放在一边。 另一方面，直接方法使用半密集像素信息而不是仅使用稀疏关键点，但最小化光度一致性损失是一个更复杂的问题，在优化过程中更容易陷入局部最小值 。相比之下，基于密集光流的方法通过将密集像素信息的重投影误差作为稳定的优化目标，结合了基于关键点和直接基于光度计的方法的优点。
<br/>

应用于移动机器人的 SLAM 方法经常结合来自车轮编码器的测量值，这是一种支持移动机器人导航的标准传感器。 根据地面材料的不同，车轮里程表可能会遇到不同程度的滑动，从而导致不同的水平测量误差。 长时间整合位姿，误差累积相当大。 相比之下，短时间内的位姿整合，更具体地说，在两个相邻关键帧的时间段内，是相当可靠的。 因此，为了增强整个系统的鲁棒性，车轮里程计的相对 2D 位姿变换被添加为连续关键帧之间的附加约束。 这些约束增加了轨迹估计的平滑度，并且在相机视图中缺少纹理时特别有用。<br/>


在室内环境中移动时，移动机器人需要依靠稠密的 3D 地图进行导航和避障。 作者使用深度相机来获取3D信息，因为现成的深度相机系统变得越来越可靠。 此外，深度相机在无纹理的室内场景中是有益的，因为它提供了用于对齐的几何信息。 简单地累积所有帧的深度点云将导致大量的信息冗余，因为相邻帧的观测结果大部分重叠。 为此，作者选择 TSDF 作为稠密 3D 地图的表示。这是一种基于体素的表示。 落入同一体素的 3D 点会被融合。 在减少冗余的同时，通过加权平均将观察噪声的影响降至最低。作者在特定时间窗口内构建分离的 TSDF 子图，这些子图可以在几何上相互对齐，为全局束调整（global BA）提供额外的约束。 结果，累积的姿势漂移可以通过闭合的长期循环来减轻。 与密集的光流约束相比，由于显着的视角和基线偏差可能会错过潜在的闭环，子图配准不受视角变化的限制，并且可以在几何上稳健地对齐地图。

![image.png](/images/test1.png "a) 白墙前的摄像头跟踪失败； b) 与车轮里程计测量融合后的平滑跟踪；c) 因错过大基线回环闭合而被错位污染的重建地图； d) 改进了带有子图配准的密集地图。")


作者还提出了一个深度图细化策略（depth map reﬁnement strategy），以提高密集重建的准确性和完整性。 观察误差相对于深度范围呈二次方增加。 在进行远距离观测时，深度测量会受到明显的观测噪声的影响，这会导致重建地图中出现大量重影和伪影，从而影响地图精度和机器人导航。 为了提高深度图质量，我们使用来自 SLAM 后端的全局 BA 的现成结果。 关键帧的优化深度图（在SLAM后端全局BA获得的深度图被成为优化深度图）受益于相邻帧之间光流的密集匹配，并且由于增加信息的联合优化而具有更高的精度。 根据 degree of over-determination，可以得出每个优化深度像素的置信度值$\omega$，在此基础上优化深度（optimized depth）与原始传感器深度自适应融合。 此外，我们应用双边求解器来增强传感器深度图的平滑度，它利用彩色图像中的外观信息来保持物体边缘的清晰度，同时平滑物体表面上的测量值（这里的意思是深度相机直接获得的深度图成为原始传感器深度，这个深度图经过一个双边求解器来增强深度图的平滑度，这样就得到了一个平滑后的深度图，用这个平滑后的深度图与在SLAM后端全局BA获得的优化深度图进行一个自适应融合，得到最终的细化深度图，融合方案如下公式所示）。

<div align=center><img src="/images/formular.png" width="  "></div>
<br/>


![image.png](/images/test2.png "从左到右：彩色图像、传感器深度图、平滑后深度图、优化的深度图和最终自适应融合后的深度图。有改进的地方和有所改善的区域用红色矩形标记")


# 主要贡献总结

- 一种新颖的鲁棒室内视觉 SLAM 框架，通过探索不同约束的相互补充性质，克服了短期纹理缺失和长期大基线循环闭合的挑战。  
- 一种基于传感器原始深度误差分析和结合颜色线索与双边求解器和全局束调整优化结果的深度图细化策略。  
- 在多个数据集和数百个序列上进行实验，以验证所提出系统的有效性。 根据高端激光扫描仪模型评估最终重建。




